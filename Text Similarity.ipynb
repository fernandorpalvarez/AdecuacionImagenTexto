{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2VEC MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 6000\n"
     ]
    }
   ],
   "source": [
    "# load a pre-defined list of photo identifiers\n",
    "def load_set(filename):\n",
    "\tdoc = load_doc(filename)\n",
    "\tdataset = list()\n",
    "\t# process line by line\n",
    "\tfor line in doc.split('\\n'):\n",
    "\t\t# skip empty lines\n",
    "\t\tif len(line) < 1:\n",
    "\t\t\tcontinue\n",
    "\t\t# get the image identifier\n",
    "\t\tidentifier = line.split('.')[0]\n",
    "\t\tdataset.append(identifier)\n",
    "\treturn set(dataset)\n",
    "\n",
    "# load training dataset (6K)\n",
    "filename = 'E://TFM/Flickr8k/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
    "train = load_set(filename)\n",
    "print('Dataset: %d' % len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clean descriptions into memory\n",
    "def load_clean_descriptions(filename, dataset):\n",
    "\t# load document\n",
    "\tdoc = load_doc(filename)\n",
    "\tdescriptions = dict()\n",
    "\tfor line in doc.split('\\n'):\n",
    "\t\t# split line by white space\n",
    "\t\ttokens = line.split()\n",
    "\t\t# split id from description\n",
    "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
    "\t\t# skip images not in the set\n",
    "\t\tif image_id in dataset:\n",
    "\t\t\t# create list\n",
    "\t\t\tif image_id not in descriptions:\n",
    "\t\t\t\tdescriptions[image_id] = list()\n",
    "\t\t\t# wrap description in tokens\n",
    "\t\t\tdesc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
    "\t\t\t# store\n",
    "\t\t\tdescriptions[image_id].append(desc)\n",
    "\treturn descriptions\n",
    "\n",
    "# descriptions\n",
    "train_descriptions = load_clean_descriptions('descriptions.txt', train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_descriptions_list = list(train_descriptions.values())\n",
    "\n",
    "# Creating data for the model training\n",
    "train_data=[]\n",
    "for i in train_descriptions_list:\n",
    "    for j in i:\n",
    "        train_data.append(j.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(train_data, size=300, min_count=2,window=5, sg=1,workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 4436\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary size\n",
    "print('Vocabulary size:', len(model.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function returning vector reperesentation of a document\n",
    "def get_embedding_w2v(doc_tokens):\n",
    "    embeddings = []\n",
    "    if len(doc_tokens)<1:\n",
    "        return np.zeros(300)\n",
    "    else:\n",
    "        for tok in doc_tokens:\n",
    "            if tok in model.wv.vocab:\n",
    "                embeddings.append(model.wv.word_vec(tok))\n",
    "            else:\n",
    "                embeddings.append(np.random.rand(300))\n",
    "        # mean the vectors of individual words to get the vector of the document\n",
    "        return np.mean(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def preprocess(s):\n",
    "    text_tokens = word_tokenize(s)\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
    "    tokens_without_sw_lw = [word.lower() for word in tokens_without_sw]\n",
    "    return tokens_without_sw_lw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance_wordembedding_method(s1, s2):\n",
    "    import scipy\n",
    "    vector_1 = get_embedding_w2v(preprocess(s1))\n",
    "    vector_2 = get_embedding_w2v(preprocess(s2))\n",
    "    cosine = scipy.spatial.distance.cosine(vector_1, vector_2)\n",
    "    print(round((1-cosine)*100,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.11 %\n"
     ]
    }
   ],
   "source": [
    "frase1 = \"child in pink dress is climbing up set of stairs in an entry way\"\n",
    "frase2 = \"girl going into wooden building\"\n",
    "frase3 = \"oh my god\"\n",
    "\n",
    "cosine_distance_wordembedding_method(frase1,frase3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRETRAINED GLOVE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(File):\n",
    "    print(\"Loading Glove Model\")\n",
    "    #f = open(File,'r')\n",
    "    f = open(File, encoding=\"utf-8\")\n",
    "    gloveModel = {}\n",
    "    for line in f:\n",
    "        splitLines = line.split()\n",
    "        word = splitLines[0]\n",
    "        wordEmbedding = np.array([float(value) for value in splitLines[1:]])\n",
    "        gloveModel[word] = wordEmbedding\n",
    "    print(len(gloveModel),\" words loaded!\")\n",
    "    return gloveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load Glove vectors\n",
    "glove_dir = 'E://TFM/Glove/glove.6B.200d.txt'\n",
    "model = loadGloveModel(glove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance_wordembedding_method(s1, s2):\n",
    "    import scipy\n",
    "    vector_1 = np.mean([model[word] for word in preprocess(s1)],axis=0)\n",
    "    vector_2 = np.mean([model[word] for word in preprocess(s2)],axis=0)\n",
    "    cosine = scipy.spatial.distance.cosine(vector_1, vector_2)\n",
    "    print(round((1-cosine)*100,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.09 %\n",
      "73.92 %\n"
     ]
    }
   ],
   "source": [
    "frase1 = \"child in pink dress is climbing up set of stairs in an entry way\"\n",
    "frase2 = \"park with childrens playing on it\"\n",
    "frase3 = \"empty park with no childrens on it\"\n",
    "frase4 = \"A park full of children playing and having fun\"\n",
    "\n",
    "cosine_distance_wordembedding_method(frase2,frase3)\n",
    "cosine_distance_wordembedding_method(frase2,frase4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
